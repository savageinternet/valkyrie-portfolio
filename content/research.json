[{
  "thumb": "airlogic-300.png",
  "title": "AirLogic: Embedding Pneumatic Computation and I/O in 3D Models to Fabricate Electronics-Free Interactive Objects",
  "titleShort": "AirLogic",
  "authors": "Valkyrie Savage, Carlos E. Tejada, Mengyu Zhong, Raf Ramakers, Daniel Ashbrook, Hyunyoung Kim",
  "venue": "UIST 2022",
  "abstract": "Researchers have developed various tools and techniques towards the vision of on-demand fabrication of custom, interactive devices. Recent work has 3D-printed artefacts like speakers, electromagnetic actuators, and hydraulic robots. However, these are non-trivial to instantiate as they require post-fabrication mechanical-- or electronic assembly. We introduce AirLogic: a technique to create electronics-free, interactive objects by embedding pneumatic input, logic processing, and output widgets in 3D-printable models. AirLogic devices can perform basic computation on user inputs and create visible, audible, or haptic feedback; yet they do not require elec- tronic circuits, physical assembly, or resetting between uses. Our library of 13 exemplar widgets can embed AirLogic-style computational capabilities in existing 3D models. We evaluate our widgets' performance—quantifying the loss of airflow (1) in each widget type, (2) based on printing orientation, and (3) from internal object geometry. Finally, we present five applications that illustrate AirLogic's potential.",
  "links": [
    {"title": "Paper", "href": "papers/airlogic.pdf"},
    {"title": "ACM Digital Library", "href": "https://dl.acm.org/doi/10.1145/3526113.3545642"},
    {"title": "Github repo", "href": "https://github.com/shape-changing-interfaces/AirLogic"},
    {"title": "Project Page", "href": "https://youtu.be/jFL-_G9vmeU"}
  ],
  "video": "https://www.youtube.com/embed/jFL-_G9vmeU"
},{
  "thumb": "doreen-300.png",
  "title": "DOREEN: A Game of Provocations Creating New Ambitions for Equity in Computing through Intertextual Design",
  "titleShort": "DOREEN",
  "authors": "Jenny-Margethe Vej, Valeria Borsotti, Valkyrie Savage, Morten Engell-Nørregård, Pernille Bjørn",
  "venue": "NordiCHI 2022",
  "abstract": "We introduce DOREEN, a norm-critical story-telling game of provocations that displays women's invisible experiences in computing to challenge barriers to inclusion. Following the principles of intertextual design, we collected empirical narratives from the past experiences of everyday women in computing and embedded these within the mechanics of role-playing storytelling games. With DOREEN we propose a playful way of exploring how gender roles, assumptions about computing, and social dynamics shape the experience of students – to reflect on the past with the aim of changing the future. DOREEN makes intertextual referencing to The Unbeatable SQUIRREL Girl aka Doreen Green, a computer science college student and a Marvel superhero who finds unorthodox ways (using wit and humor) to overcome barriers. DOREEN is a game to enjoy while engaging in critical reflection on belonging and well-being within computing. DOREEN is centered around an octahedron die and an adventure sheet inspired by tabletop role-playing gaming, emphasizing story-telling as a strategy for challenging norms and creating alternative narratives. The die design invites the players to reflect on how the probability of encountering limiting narratives and structural barriers can be higher or lower for different social groups. Finally, DOREEN is designed as the embodiment of all the people whose experiences, agency, and perspectives should be included in the journey of broadening participation in computing.",
  "links": [
    {"title": "ACM Digital Library", "href": "https://dl.acm.org/doi/10.1145/3546155.3547289"},
    {"title": "Project Page", "href": "http://www.femtech.dk/artifacts/doreen/"},
    {"title": "Instructable", "href": "https://www.instructables.com/Conversation-Oktahedron/"}
  ],
  "video": ""
},{
  "thumb": "renderpanel-300.png",
  "title": "Fabricate it or Render it?",
  "titleShort": "Render Panel",
  "authors": "Mustafa Doga Dogan, Patrick Baudisch, Hrvoje Benko, Michael Nebeling, Huaishu Peng, Valkyrie Savage, Stefanie Mueller",
  "venue": "CHI 2022",
  "abstract": "In the technical human-computer interaction (HCI) community, two research fields that gained significant popularity in the last decade are digital fabrication and augmented/virtual reality (AR/VR). Although the two fields deal with different technical challenges, both aim for a single end goal: creating ”objects” instantly – either by fabricating them physically or rendering them virtually. In this panel, we will discuss the pros and cons of both approaches, discuss which one may prevail in the future, and what opportunities exist for closer collaboration between researchers from the two research fields.",
  "links": [
    {"title": "ACM Digital Library", "href": "https://dl.acm.org/doi/abs/10.1145/3491101.3516510"},
    {"title": "Video", "href": "https://youtu.be/e3gfy11d76s?t=24112"}
  ],
  "video": "https://www.youtube.com/embed/jFL-_G9vmeU"
},{
  "thumb": "wrist-300.png",
  "title": "Sensing Hand Interactions with Everyday Objects by Profiling Wrist Topography",
  "titleShort": "Wrist Profiling",
  "authors": "Julius Rudolph, Ricardo Jota, Bruno de Araujo, David Holman, Daniel Wigdor, Valkyrie Savage",
  "venue": "TEI 2022",
  "abstract": "We demonstrate rich inferences about unaugmented everyday objects and hand object interactions by measuring minute skin surface deformations at the wrist using a sensing technique based on capacitance. The wristband prototype infers muscle and tendon tension, pose, and motion, which we then map to force (9 users, 13.66 +/- 9.84 N regression error on classes 0--49.1 N), grasp (9 users, 81 +/- 7 % classification accuracy on 6 grasps), and continuous interaction (10 users, 99 +/- 1 % discrimination accuracy between 6 interactions, 89--97 % accuracy on 3 states within each interaction) using basic machine learning models.\n\nWe wrapped these sensing capabilities into a proof-of-concept end-to-end system, Ubiquitous Controls, that enables virtual range inputs by sensing continuous interactions with unaugmented objects. Eight users leveraged our system to control UI widgets (like sliders and dials) with object interactions (like \"cutting with scissors\" and \"squeezing a ball\"). Finally, we discuss the implications and opportunities of using hands as a ubiquitous sensor of our surroundings.",
  "links": [
    {"title": "Paper", "href": "papers/wristprofiling.pdf"},
    {"title": "Workshop Paper", "href": "http://epo4vr.dfki.de/assets/papers/rudolph2021handasasensor.pdf"},
    {"title": "ACM Digital Library", "href": "https://dl.acm.org/doi/10.1145/3490149.3501320"},
    {"title": "Video", "href": "https://vimeo.com/653855552"}
  ],
  "video": "https://player.vimeo.com/video/653855552?h=8c9c1beb2f"
},{
  "thumb": "fabbed-300.jpg",
  "title": "Fabbed to Sense: Integrated Design of Geometry and Sensing Algorithms for Interactive Objects",
  "titleShort": "Fabbed to Sense",
  "authors": "Valkyrie Savage",
  "venue": "Dissertation",
  "abstract": "Task-specific tangible input devices, like video game controllers, improve user speed and accuracy in input tasks compared to the more general-purpose touchscreen or mouse and keyboard. However, while modifying a graphical user interface (GUI) to accept mouse and keyboard inputs for new and specific tasks is relatively easy and requires only software knowledge, tangible input devices are challenging to prototype and build.\n\nRapid prototyping digital fabrication machines, such as vinyl cutters, laser cutters, and 3D printers, now permeate the design process for such devices. Using these tools, designers can realize a new tangible design faster than ever. In a typical design process, these machines are not used to create the interaction in these interactive product prototypes: they merely create the shell, case, or body, leaving the designer to, in an entirely separate process, assemble and program electronics for sensing a user's input. What are the most cost-effective, fast, and flexible ways of sensing rapid-prototyped input devices? In this dissertation, we investigate how 2D and 3D models for input devices can be automatically generated or modified in order to employ standard, off-the-shelf sensing techniques for adding interactivity to those objects: we call this \"fabbing to sense.\"\n\nWe describe the capabilities of modern rapid prototyping machines, linking these abilities to potential sensing mechanisms when possible. We plunge more deeply into three examples of sensing/fabrication links: we build analysis and design tools that help users design, fabricate, assemble, and <i>use</i> input devices sensed through these links. First, we discuss Midas, a tool for building capacitive sensing interfaces on non-screen surfaces, like the back of a phone. Second, we describe Lamello, a technique that generates lasercut and 3D printed tine structures and simulates their vibrational frequencies for training-free audio sensing. Finally, we present Sauron, a tool that automatically modifies the interior of 3D input models to allow sensing via a single embedded camera. We demonstrate each technique's flexibility to be used for many types of input devices through a series of example objects.",
  "links": [
    {"title": "Paper", "href": "papers/thesis.pdf"},
    {"title": "Presentation Video", "href": "https://www.youtube.com/watch?v=SgZUxloEo4s"}
  ],
  "video": "https://www.youtube.com/embed/SgZUxloEo4s"
},{
  "thumb": "drillsergeant-300.png",
  "title": "Drill Sergeant: Supporting Physical Construction Projects through an Ecosystem of Augmented Tools",
  "titleShort": "Drill Sergeant",
  "authors": "Eldon Schoop, Michelle Nguyen, Daniel Lim, Valkyrie Savage, Sean Follmer, Björn Hartmann",
  "venue": "CHI 2016 EA",
  "abstract": "Mapping techniques from software tutorials onto physical craft processes can assist novices in building multi-material assemblies. By providing in-situ step instructions and progress tracking, generating dynamic feedback on technique, and adapting tutorial content to a user's specific context and preferences, an ecosystem of smart tools can guide users through complete project tutorials. We demonstrate how such techniques can be enabled by augmenting common workshop tools (drill/driver, saw, router) with measurement, state sensing and interactive feedback; and by sequencing instructions across multiple tools. We validate the benefits of a smart tool ecosystem through reflections on a series of author-created design examples and informal feedback from four fab lab users.",
  "links": [
    {"title": "ACM Digital Library", "href": "http://dl.acm.org/citation.cfm?id=2892429"},
    {"title": "Paper", "href": "papers/drillsergeant.pdf"},
    {"title": "Video", "href": "https://www.youtube.com/watch?v=y8Qvgf1dBqA"}
  ],
  "video": "https://www.youtube.com/embed/y8Qvgf1dBqA"
},{
  "thumb": "3dp-300.png",
  "title": "3-D Printing Interactive Devices",
  "titleShort": "Printing Interactive Devices",
  "authors": "Valkyrie Savage",
  "venue": "XRDS Spring 2016",
  "abstract": "Today's 3-D printing hobbyists churn out kilos of static trinkets. These existing machines can further help them create functional objects, if new perspectives and designs are employed.",
  "links": [
    {"title": "ACM Digital Library", "href": "http://dl.acm.org/citation.cfm?id=2893495"}
  ],
  "video": ""
},{
  "thumb": "mmarks-300.jpg",
  "title": "Makers' Marks: Physical Markup for Designing and Fabricating Functional Objects",
  "titleShort": "Makers' Marks",
  "authors": "Valkyrie Savage, Sean Follmer, Jingyi Li, Björn Hartmann",
  "venue": "UIST 2015",
  "abstract": "To fabricate functional objects, designers create assemblies combining existing parts (e.g., mechanical hinges, electronic components) with custom-designed geometry (e.g., enclosures). Modeling complex assemblies is outside the reach of the growing number of novice \"makers\" with access to digital fabrication tools. We aim to allow makers to design and 3D print functional mechanical and electronic assemblies. Based on a formative exploration, we created Makers' Marks, a system based on physically authoring assemblies with sculpting materials and annotation stickers. Makers physically sculpt the shape of an object and attach stickers to place existing parts or high-level features (such as parting lines). Our tool extracts the 3D pose of these annotations from a scan of the design, then synthesizes the geometry needed to support integrating desired parts using a library of clearance and mounting constraints. The resulting designs can then be easily 3D printed and assembled. Our approach enables easy creation of complex objects such as TUIs, and leverages physical materials for tangible manipulation and understanding scale. We validate our tool through several design examples: a custom game controller, an animated toy figure, a friendly baby monitor, and a hinged box with integrated alarm.",
  "links": [
    {"title": "ACM Digital Library", "href": "http://dl.acm.org/citation.cfm?id=2807508"},
    {"title": "Paper", "href": "papers/makers-marks.pdf"},
    {"title": "Video", "href": "https://www.youtube.com/watch?v=xzKKK6yF5Dw"}
  ],
  "video": "https://www.youtube.com/embed/xzKKK6yF5Dw"
},{
  "thumb": "lamello-300.jpg",
  "title": "Lamello: Passive Acoustic Sensing for Tangible Input Components",
  "titleShort": "Lamello",
  "authors": "Valkyrie Savage, Andrew Head, Björn Hartmann, Dan Goldman, Gautham Mysore, Wilmot Li",
  "venue": "CHI 2015",
  "abstract": "We describe Lamello, an approach for creating tangible input components that recognize user interaction via passive acoustic sensing. Lamello employs comb-like structures with varying-length tines at interaction points (e.g., along slider paths). Moving a component generates tine strikes; a real-time audio processing pipeline analyzes the resultant sounds and emits high-level interaction events. Our main contributions are in the co-design of the tine structures, information encoding schemes, and audio analysis. We demonstrate 3D printed Lamello-powered buttons, sliders, and dials.",
  "links": [
    {"title": "ACM Digital Library", "href": "http://dl.acm.org/citation.cfm?id=2702207"},
    {"title": "Paper", "href": "papers/lamello.pdf"},
    {"title": "Video", "href": "https://www.youtube.com/watch?v=695ke7P6HM4"}
  ],
  "video": "https://www.youtube.com/embed/695ke7P6HM4"
},{
  "thumb": "sot-300.png",
  "title": "A Series of Tubes: adding interactivity to 3D prints using internal pipes",
  "titleShort": "A Series of Tubes",
  "authors": "Valkyrie Savage, Ryan Schmidt, Tovi Grossman, George Fitzmaurice, Björn Hartmann",
  "venue": "UIST 2014",
  "abstract": "3D printers offer extraordinary flexibility for prototyping the shape and mechanical function of objects. We investigate how 3D models can be modified to facilitate the creation of interactive objects that offer dynamic input and output. We introduce a general technique for supporting the rapid prototyping of interactivity by removing interior material from 3D models to form internal pipes. We describe this new design space of pipes for interaction design, where variables include openings, path constraints, topologies, and inserted media. We then present PipeDream, a tool for routing such pipes through the interior of 3D models, integrated within a 3D modeling program. We use two distinct routing algorithms. The first has users define pipes' terminals, and uses path routing and physics-based simulation to minimize pipe bending energy, allowing easy insertion of media post-print. The second allows users to supply a desired internal shape to which we fit a pipe route: for this we describe a graph-routing algorithm. We present several prototypes created using our tool to show its flexibility and potential.",
  "links": [
    {"title": "ACM Digital Library", "href": "http://dl.acm.org/citation.cfm?id=2647374"},
    {"title": "Paper", "href": "papers/series-of-tubes.pdf"},
    {"title": "Video", "href": "https://www.youtube.com/watch?v=PiFbjOkYC4M"},
    {"title": "Patent", "href": "https://patents.google.com/patent/US20150370926"}
  ],
  "video": "https://www.youtube.com/embed/PiFbjOkYC4M"
},{
  "thumb": "sauron-300.png",
  "title": "Sauron: embedded single-camera sensing of printed physical user interfaces",
  "titleShort": "Sauron",
  "authors": "Valkyrie Savage, Colin Chang, Björn Hartmann",
  "venue": "UIST 2013",
  "abstract": "3D printers enable designers and makers to rapidly produce physical models of future products. Today these physical prototypes are mostly passive. Our research goal is to enable users to turn models produced on commodity 3D printers into interactive objects with a minimum of required assembly or instrumentation. We present Sauron, an embedded machine vision-based system for sensing human input on physical controls like buttons, sliders, and joysticks. With Sauron, designers attach a single camera with integrated ring light to a printed prototype. This camera observes the interior portions of input components to determine their state. In many prototypes, input components may be occluded or outside the viewing frustum of a single camera. We introduce algorithms that generate internal geometry and calculate mirror placements to redirect input motion into the visible camera area. To investigate the space of designs that can be built with Sauron along with its limitations, we built prototype devices, evaluated the suitability of existing models for vision sensing, and performed an informal study with three CAD users. While our approach imposes some constraints on device design, results suggest that it is expressive and accessible enough to enable constructing a useful variety of devices.",
  "links": [
    {"title": "ACM Digital Library", "href": "http://dl.acm.org/citation.cfm?id=2501992"},
    {"title": "Paper", "href": "papers/sauron.pdf"},
    {"title": "Video", "href": "https://www.youtube.com/watch?v=GNdCnmm-cw8"}
  ],
  "video": "https://www.youtube.com/embed/GNdCnmm-cw8"
},{
  "thumb": "midas-300.png",
  "title": "Midas: fabricating custom capacitive touch sensors to prototype interactive objects",
  "titleShort": "Midas",
  "authors": "Valkyrie Savage, Xiaohan Zhang, Björn Hartmann",
  "venue": "UIST 2012",
  "abstract": "An increasing number of consumer products include user interfaces that rely on touch input. While digital fabrication techniques such as 3D printing make it easier to prototype the shape of custom devices, adding interactivity to such prototypes remains a challenge for many designers. We introduce Midas, a software and hardware toolkit to support the design, fabrication, and programming of flexible capacitive touch sensors for interactive objects. With Midas, designers first define the desired shape, layout, and type of touch sensitive areas, as well as routing obstacles, in a sensor editor. From this high-level specification, Midas automatically generates layout files with appropriate sensor pads and routed connections. These files are then used to fabricate sensors using digital fabrication processes, e.g., vinyl cutters and conductive ink printers. Using step-by-step assembly instructions generated by Midas, designers connect these sensors to the Midas microcontroller, which detects touch events. Once the prototype is assembled, designers can define interactivity for their sensors: Midas supports both record-and-replay actions for controlling existing local applications and WebSocket-based event output for controlling novel or remote applications. In a first-use study with three participants, users successfully prototyped media players. We also demonstrate how Midas can be used to create a number of touch-sensitive interfaces.",
  "links": [
    {"title": "ACM Digital Library", "href": "http://dl.acm.org/citation.cfm?id=2380189"},
    {"title": "Paper", "href": "papers/midas.pdf"},
    {"title": "Video", "href": "https://www.youtube.com/watch?v=lS60AH2_Pbs"}
  ],
  "video": "https://www.youtube.com/embed/lS60AH2_Pbs"
}]
