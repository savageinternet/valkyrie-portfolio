<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>Sensing Hand Interactions with Everyday Objects by Profiling Wrist Topography - Valkyrie Savage&#x27;s Research</title>
  <meta name="description" content="Valkyrie Savage, PhD, works in physical, digital, visual, gameful, and educational research, prototyping, and design." />
  <meta name="robots" content="index, follow">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="/css/style.css" />
</head>
<link rel="stylesheet" type="text/css" href="/css/researchPage.css" />
<body>
<div id="root">
  <div id="header">
    <ul id="nav">
      <li><a href="/#about">About</a></li>
      <li><a href="/#research">Research</a></li>
      <li><a href="/#portfolio">Portfolio</a></li>
      <li><a href="/#contact">Contact</a></li>
    </ul>
    <div id="logo">
      <a href="/"><img src="/img/logo.svg" /></a>
      <div id="topbar-text"><a href="/">Valkyrie A. Savage, PhD</a></div>
    </div>
  </div>
  <div id="body">
    <div id="main">
      <section id="project-info">
        <div id="project-thumbnail">
          <img class="project-image" src="/img/research/wrist-300.png" />
        </div>
        <div id="project-text">
          <div id="title">Sensing Hand Interactions with Everyday Objects by Profiling Wrist Topography</div>
          <div id="authors">Julius Rudolph, Ricardo Jota, Bruno de Araujo, David Holman, Daniel Wigdor, Valkyrie Savage</div>
          <div id="venue">TEI 2022</div>
          <div id="links">
              <a href="https://dl.acm.org/doi/10.1145/3490149.3501320">ACM Digital Library</a><br/>
              <a href="papers/wristprofiling.pdf">Paper</a><br/>
              <a href="http://epo4vr.dfki.de/assets/papers/rudolph2021handasasensor.pdf">Workshop Paper</a><br/>
              <a href="https://vimeo.com/653855552">Video</a><br/>
          </div>
        </div>
      </section>
      <section id="project-description" class="dark-bg">
        <p class="bodytext">
          We demonstrate rich inferences about unaugmented everyday objects and hand object interactions by measuring minute skin surface deformations at the wrist using a sensing technique based on capacitance. The wristband prototype infers muscle and tendon tension, pose, and motion, which we then map to force (9 users, 13.66 +/- 9.84 N regression error on classes 0--49.1 N), grasp (9 users, 81 +/- 7 % classification accuracy on 6 grasps), and continuous interaction (10 users, 99 +/- 1 % discrimination accuracy between 6 interactions, 89--97 % accuracy on 3 states within each interaction) using basic machine learning models.

We wrapped these sensing capabilities into a proof-of-concept end-to-end system, Ubiquitous Controls, that enables virtual range inputs by sensing continuous interactions with unaugmented objects. Eight users leveraged our system to control UI widgets (like sliders and dials) with object interactions (like &quot;cutting with scissors&quot; and &quot;squeezing a ball&quot;). Finally, we discuss the implications and opportunities of using hands as a ubiquitous sensor of our surroundings.
        </p>
      </div>
      <section id="project-video">
        <iframe width="800" height="450" src="https://player.vimeo.com/video/653855552?h=8c9c1beb2f" frameborder="0" allowfullscreen></iframe>
      </div>
    </div>
  </div>
</div>
</body>
</html>
